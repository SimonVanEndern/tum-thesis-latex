% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.
\chapter{Design and Implementation}\label{chapter:design}

\section{Technology Stack}
In order to implement the architecture proposed in chapter \ref{chapter:method} we chose Android as end user device platform. Android has the highest market share \cite{android-market-share} among mobile devices and offers a healthy ecosystem of frameworks and libraries that simplify development. Furthermore we opted for an implementation in Kotlin to reduce boilerplate code and improve readability.

As server side technology we chose node.js in conjunction with a mongoDB object store database. A NoSQL database like mongoDB provides flexibility and easy adaption of data schemes without much overhead and thus perfectly fits our prototyping purpose. We chose node.js out of the same reasons. In contrast to a statically typed language, javascript provides more flexibility and ease of change. Furthermore node.js is often used in combination with mongoDB and provides seamingless integration.

The results can be made available to the public either via a dedicated route of the server or directly through granting right access to the respective collection\footnote{A collection in an object store is the equivalent to a table in a SQL database} of the database.

\section{Android Application}
The Android application targets Android Oreo (API level 27) and requires a minimum API level of 19. Approximately 96.8\% of devices run on this or a higher version of Android \cite{android-api-level-share} which allows our application to be installed on the majority of Android devices.
Furthermore, the application leverages Goolge Play Services to obtain GPS and activity data. Without Google Play Services installed, the application will not work. In order to ease future adaptability, we chose to use the Dagger2\footnote{https://dagger.dev/} framework for dependency injection in order to decouple classes as far as possible. Further use of frameworks and libraries will be explained in the following respective sections.

Th application is aimed to collect GPS data, detect the user's current activity and count the user's steps. The data collection process happens in the background without any user interaction needed. Aggregation requests to aggregate data accross devices are also served without any user interaction needed.
The android application can be grouped into three main parts of loosely coupled modules:
\begin{itemize}
	\item A module responsible for collecting and saving raw data
	\item A module responsible for locally aggregating raw data
	\item A module responsible for communicating with the server and handling aggregation requests
\end{itemize}
The control flow as depicted in figure XX is as follows: 
The application has only one Main Activity in order to ask the user to allow location access and start the background services. Apart from that the only Activity does not serve any specific purpose. 
The local aggregation as well as the polling of new requests from the server happens in the background on a 15 minute interval. The Android Workmanager controls this periodic work without any user interaction being required.

For the App in order to have maximum possibilities collecting esspecially GPS data and preventing the Android operating system from shutting down when not interacted with by the user (which is usually never the case), a non-dismissible status notification is displayed at all time. (Compare to the non-dismissible status notification displayed by Google Maps when the navigation system is active). Also the application is registered to be automatically restarted upon boot\footnote{From Android XX on, all apps are automatically managed by the battery manager which restricts background launches. The user has to switch this option to manually manage in order to allow the app to function in the way it was designed.} and also when the application is closed by the user (e.g. via the task manager) so that once installed, no further user interaction is necessary.
Furthermore, the application, respectively each module is heavily unit tested in norder to guarantee functionality and facilitate further development by other research teams. Unit and integration tests are based on AndroidJUnit4 and the expresso\footnote{https://developer.android.com/training/testing/espresso} framework.

\subsection{Separation of concerns regarding data collection and aggregation}
We choose to separate the aggregation and collection of location data in order to decouple the modules and provide the possibility to extend the model of aggregated data in the future without the need to change the raw data model. Vice versa the data collection process can be modified without impacting the aggregation process.

\subsection {Data collection}
We use the Android Room Persistence library\footnote{https://developer.android.com/topic/libraries/architecture/room} to locally store data. The library provides a layer over the standard LiteSQL database commonly used in many Android applications. We collect three types of data:
\begin{itemize}
	\item Steps: If available, the phone's internal step sensor provides updates on a regular basis. The step sensor always informs about the total number of steps since the last reboot. Upon each time we receive data from the step sensor, this data is stored directly in the \textit{step\_counter\_table}.
	\item User's activities: The Google Play Services  activity recognition API leverages different data and sensors available on the phone in order to inform about the most probable current activity of the user as one of \textit{still, walking, running, in a vehicle, on bicycle}. Whenever there is a change detected, two events are fired - one for exiting the former and one for entering the current activity. The events might not be dispatched instantly but contain the timestamp of the exact occurence. Upon each received event, this data is stored directly in the \textit{activity\_transition\_table}.
	\item GPS positions: GPS data is retrieved through the \textit{FusedLocationProviderClient} which leverages cellphone-tower and WIFI data apart from GPS to determine the position. In order to limit battery consumption, GPS data is only requested every minute if the device's detected activity is \textit{still}\footnote{Neertheless, if other applications request a GPS position, our application also receives this data, even if it occurs on a faster interval}. If the current detected activity is \textit{walking}, the interval is set to 5 seconds and in any other state, the interval is set to every second. The data is stored in the linked tables \textit{gps\_data\_table} and \textit{gps\_location\_table}. We choosse to separate the GPS point itself from the timestamp having in mind that future aggregations might need or leverage the separation of spatial data and time and more than one event might be attached to the same GPS point.
\end{itemize}

\subsection{Local data aggregation}
From the received values of the step counter since last reboot saved in \textit{step\_counter\_table} the daily steps are computed and stored in \textit{steps\_table}. The exit and enter events received via the activity recognition framework and stored in the \textit{activity\_transition\_table} are matched in order to compute activities with start and duration. Those activities are then saved in the \textit{activity\_table}.
GPS data is used to compute trajectories through the following algorithm:
\begin{enumerate}
	\item When there are more than 10 minutes between two subsequent GPS points in the sequence of all GPS points to be processed, the sequence is separated into two separate sequences and each is processed separately as a possible trajectory in the next step.
	\item First, we identify still moments - periods of no movement - as follows:
	\begin{enumerate}
		\item For each GPS point, we identify a subsequent GPS point that was registered at least two minutes after the first one.
		\item If the average speed between those two points was below 0.6 m/s, the pair is added to a list to be processed in the next step.
		\item The list of pairs of GPS points resulting from the last step is fused into sequences of GPS points as long as possible: Whenever two pairs overlap in their timestamp, they are fused to a new pair covering the combined timespan.
	\end{enumerate}
	\item The resultig GPS pairs of still moments are used to exclude still moments from the original sequence and divide it into subsequences marking trajectories.
\end{enumerate}
Of each trajectory, the start and end location as well as the respective timestamp are then saved in \textit{trajectory\_table}. We tested 0.5 m/s, 0.6 m/s and 0.7 m/s as threshold in step 2b) and found 0.6 m/s to be best fit the tested sample. On the one hand the threshold must be low enough to still include slow walking which might be below 1 m/s. On the other hand, the threshold should not be too low because inaccuracy in GPS data might otherwise induce trajectories where the device has actually not moved at all.

Example of algorithm (TODO):
\begin{verbatim}
{
	Original dataset:			
	Latitude Longitude Time
	44		 11		   10:11:03
	44.5	 11.1	   10:11:15
	44.4	 11.05	   10:12:12
	44.3	 11.07	   10:33:00
	44	     11.2	   10:34:00
}
\end{verbatim}

\subsection{Serving aggregation requests}
We use the retrofit2 framework\footnote{https://square.github.io/retrofit/} based on OKHTTP\footnote{https://square.github.io/okhttp/} to handle communication with our REST server dexribed in \ref{server}. An HTTP Interceptor is used to modify incoming and outgoing requests. The interceptor decrypts the request body of incoming messages using the private key of the installation before the body is parsed into Java Objects. On outgoing messages the inteerceptor adds authentication before sending them to the server.
The app polls for new aggregation requests every 15 minutes. New aggregation requests are first stored locally in the database. Those requests are then processed and the results are again stored locally as pending outgoing requests until they are finally send to the server. Figure XX illustrates this process. This separation of concerns is useful especially in case of an interrupted communication during processing the aggregation request. When the results cannnot be send to the server, the app automatically retries the next time that the communication module is invoked.
The aggregation itself takes the type parameter of the request to specify which actions to take on the three fields (n:int, value:Float, valueList: List<Float>) shared across all aggregation requests. In case of the tyes "steps" and "activity\_X" the field value contains the current mean of the data and the field n is the number of participants so far. In case of "stepsListing" only the field "valueList" is used. Each user's mean value is added to the list. In case of "trajectories", only the field "valueList" is used. Four subsequent elements of the list always represent one trajectory as of latitude of start, longitude of start, latitude of end and longitude of end.

In case that the aggregation should be changed to actually work over P2P e.g. using local WIFI networks this module only has to be adapted to the new routing of requests. No further changes to the application are necessary.
%In case of edge-computing, ... only this module has to be adapted to receive the requets from and send them to the respective endpoints and the system works fine.

\subsection{API}
// Move to beginning of chapter before Android appllication
The API is designed as a pure JSON API.
The API consists of the following endpoints:
\begin{itemize}
	\item POST /user - for creating a new user
	\item GET /requests - for retrieving aggregation requests for a user
	\item POST /forward - for sending a processed aggregation request back to the server
	\item GET /aggregations - for retrieving all completed aggregation results
	\item POST /admin/sampleRequest - for starting a new aggregation request.
\end{itemize}

The routes used for interaction with the application (except the one for creating a new user) are secured and can only be used if the users can successfully be authenticated. The routes for starting new aggregation requests and retrieving all results require administration authentication. The route for the results was designed to be available to the public without authentication but restricted in our setting to avoid privacy issues that might evolve due to the experimental request.
Figure XX depicts an example usage of each of those endpoints. There are some other routes that are only used for debugging purposes. 

\section{Data aggregation design}
All aggregation requests have in common that the underlying data is specified through start day and end day. Thus the minimum timespan for an aggregation is 24 hours. All other timespans are multiples of 24 hours.
The following aggregation requests were implemented:
\begin{enumerate}
	\item Computing the average number of steps walked.
	\item Computing the average time spent walking, in a vehicle or on a bicycle\footnote{https://developers.google.com/android/reference/com/google/android/gms/location/DetectedActivity}.
	\item Aggregating a list of the average number of steps walked during the timespan of each user.
	\item Aggregating a list of all trajectories registered by the users phone.
\end{enumerate}

We had no doubt that aggregation 1 and 2 do not pose any privacy risk to the users participating in the aggregation. Aggregation 3 was implemented to test whether this type of aggregation, which allows for more advances statistical computations as median values and distribution properties, still completely preserves privacy.
Aggregation 4 imposes a privacy risk discussed in XX on the user and was implemented in order to get an overview of the data quality of our setup and validate the feasability of the other aggregation requests proposed in XX.

\section{Server Design and Implementation}\label{server}
The server is build using the event-driven node.js verion 10.15.3 leveraging the express\footnote{https://expressjs.com/} web-server framework and using the mocha\footnote{https://mochajs.org/} testing framework in combination with the chai\footnote{https://www.chaijs.com/} assertion library for unit and integration testing. The layered architecture starts with the server - server.js handling authentication and updating the respective users lastSeen property. Afterwards routes.js connects each API endpoint to the respective function in requests.js which contains the overall logic of the endpoint. The repository module than handles those requests according to the underlying datamodels and persists data in a mongoDB object store. server.js also invokes a scheduled task which re-routes stale requests where the user has not proceeded with the pending request either due to being offline or due to a problem handling the request. When new aggregation requests are started, the lastSeen timestamp of users is taken into account to exclude users that have not connected for a certain time. Furthermore, the list of users who are selected to serve the new request is ordered by the time the user was last seen.

\subsection{Data Model}
We organize the data in four collections. The user collection stores the user data which is the public key, the hashed password and "lastSeen" - the timestamp of the last interaction of the user with the server. Aggregation requests are split into two collections. The collection "rawAggregationRequests" stores the initial aggregation request inserted through the admin interface containing the fields start, end, type - the type of the request, the three fields n, value, valueList reused across all aggregations to pass data, the timestamp when the request was filed to the server and a flag indicating whether this request has been started yet\footnote{E.g. when the end data of a newly inserted aggregation request is in the future, the request will be started only when this day has passed}. Upon start of the aggregation request, a list of the 10 most recently active users is retrieved in order to serve this request. The request body is then encrypted with the first users public key and stored in the collection "aggregationRequests". Each time, a user requests an aggregationRequest, proceeds with it and sends the results back to the server, the result is inserted into the database as a new aggregationRequest. The fields of this collection are 
\begin{itemize}
	\item rawRequestId - The id of the related rawRequest. This field is not available through the API.
	\item started\_at - The timestamp, when the request has been started
	\item publicKey - The public key of the user that should proceed this request
	\item nextUser - The public key of the user that will receive the request afterwards. This is necessary so that the user that should proceed this request can encrypt the processed request with the public key of the next user.
	\item previousRequest - The id of the previous request. This is null, if it is the first request in the chain. This is used for the mechanism taking care if a request is not processed by the user it is pending for.
	\item users - the list of public keys of the following users that will proceed with this request. This field is not available through the API.
	\item encryptionKey - A synchronous key, encrypted with the public key of the user the request is aimed at.
	\item iv - the initialization vector used for synchronous encryption and decryption of the actual aggregation request.
	\item encryptedRequest - The actual aggregation request encrypted with the synchronous key.
	\item timestamp - The timestamp when this object has been created.
	\item commpleted - A flag indicating whether this aggregation request has already been proceeded by the respective user and the resulting aggregationRequest has been received by the server.
\end{itemize}
The last collection called "aggregationResults" is used to store the results of an aggregation request. Once there are no more users to serve an aggregationRequest, the last user sends the final data unencrypted to the server where it is stored as an aggregationResult. It contains the same fields as the rawAggregationRequest except the started flag and additionally a field started\_at and timestamp - indicating when the aggregation request referenced through rawRequestId was started and when it was completed.