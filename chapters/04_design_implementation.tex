% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.
\chapter{Design and Implementation}\label{chapter:design}

\section{Technology Stack}
In order to implement the architecture proposed in chapter \ref{chapter:design} we chose Android as end user device platform. Android has the highest market share among mobile devices and offers a healthy ecosystem of frameworks and libraries that simplify development. Furthermore we opted for an implementation in Kotlin to reduce boilerplate code and improve readability.

As server side technology we chose node.js in conjunction with a mongoDB object store database. A NoSQL database like mongoDB provides flexibility and easy adaption of data schemes without much overhead and thus perfectly fits our prototyping purpose. We chose node.js out of the same reasons. In contrast to a statically typed language, javascript provides more flexibility and ease of change. Furthermore node.js is often used in combination with mongoDB and probably provides the best integration of it.

The results can be made available to the public either via a dedicated route of the server or directly through granting right access to the respective collection of the database.

\section{Android Application}
The Android application is aimed to collect gps and other location data in the background without any user interaction needed and serve aggregation requests also without any user interaction needed.
The android application can be grouped into three main parts:
\begin{itemize}
	\item A module responsible for collecting location data
	\item A module responsible for locally aggregating the raw data
	\item A module responsible for handling aggregation requests
\end{itemize}
The application is programmed with API level XX as target level and a minimum Android API level of XX. Approximately XX\% of devices support this minimum API level which allows our application to be installed on almost any Android device.
Furthermore, the application leverages google services. Without google play services, the application will not work. In order to ease future adaptability, we chose to use the Dagger2 framework for dependency injection. Further use of frameworks and libraries will be explained in the following respective sections. 

\subsection{Separation of concerns regarding location data}
We chose to separate the aggregation and collection of location data in order to decouple the modules and provide the possibility to extend the model of aggregated data in the future without the need to chose the raw data model. Vice versa the data collection process can be modified without impacting the aggregation process.

\subsection{Overall Android Architecture}
The application has only one Main Activity in order to ask the user to grant location access. Apart from that the only Activity does not serve any specific purpose. It displays the 10 most recent database entries for some tables, used during the development and testing process.
The application itself is structured into loosely coupled modules taking care of retrieving and saving the raw data, locally aggregating the data and communicating with the server.
The local aggregation as well as the polling of new requests from the server happens on a 15 minute interval. The Android Workmanager controls this periodic work.
For the App in order to have maximum possibilities collecting esspecially GPS data and preventing the Android operating system from shutting down when not interacted with by the user (which is usually never the case), a non-dismissible status notification is displayed at all time. (Compare to the non-dismissible status notification displayed by Google Maps when the navigation system is active). Also the application is registered to be automatically restarted upon boot\footnote{From Android XX on, all apps are automatically managed by the battery manager which restricts background launches. The user has to switch this option to manually manage in order to allow the app to function in the way it was designed.} so that once installed, no further user interaction is necessary.
Furthermore, the application, respectively each module is heavily unit tested in norder to guarantee functionality and facilitate further development by other research teams. Unit tests are based on JUnnit 4 for Android and expresso.

\subsection {Data collection}
We use the Android Room Persistence library which is a layer on top of the standard LiteSQL database used in most Android applications. We collect three types of data:
\begin{itemize}
	\item Steps: If available, the phone internal step sensor provides updates on a regular basis choosen by the user. We chose XX minutes as update interval. The step sensor always retrieves the total number of steps since last reboot. Upon each time we receive data from the step sensor, this data is stored directly in the "steps\_raw" table.
	\item Current activity: The google services activity recognition API leverages different data and sensors available on the phone in order to inform about the current activity as one of [STILL, WALKING, IN\_VEHICLE, ON\_BYCICLE]. Whenever there is a change detected, two events are fired - one for exiting the former and one for entering the current activity. The events might not be dispatched instantly but contain the timestamp of the exact occurence. Upon each received event, this data is stored directly in the "activity\_raw" table.
	\item GPS positions: GPS data is collected via the GPSFusedLocationProvider which leverages cellphone-tower and WIFI data apart from GPS to determine the position. In order to limit battery consumption, GPS data is only requested every 5 minutes if the device is idle. \footnote{Neertheless, if other applications request a GPS position, our application also receives this data, even if it occurs on a faster interval than our set interval} If the device is in state WALKING (see last item), the interval is set to XX seconds and in any other state, the interval is set to every second. The data is stored in the linked tables XX and XX. We chose to separate the GPS point itself from the timestamp having in mind that future aggregations might need or leverage the separation of spatial data and time. Especially regarding the high load of data - up to several 10 thousand GPS points per day.
\end{itemize}

\subsection{Local data aggregation}
Steps are simply aggregated on a daily basis and stored in the steps table. The exit and enter events received via the activity recognition framework and stored in the XX table are matched in order to compute activities with start and duration. Those are then saved in the "activity" table.
GPS data is currently only used to compute trajectories via the following algorithm:
\begin{enumerate}
	\item When there are more than 10 minutes between two subsequent GPS points in the sequence of GPS points to be processed, the sequence is separated into two separate possible trajectories and each is processed separately in the next step.
	\item First we identify still moments - periods of no movement - as follows:
	\begin{enumerate}
		\item For each GPS point, the next point that was registered at least two minutes after the first one is identified.
		\item If the average speed between those two points was below 0.6 m/s, the pair is added to a list.
		\item After iterating over all GPS points, the list resulting from the last step is fused into sequences as long as possible.
	\end{enumerate}
	\item Those sequences / still moments are cut out of the original sequence. The remaining subsequences are our trajectories.
\end{enumerate}
The start and end location as well as time of those trajectories is then saved in the "trajectory" table.

Example of algorithm:
\begin{verbatim}
{
	Original dataset:			
	Latitude Longitude Time
	44		 11		   10:11:03
	44.5	 11.1	   10:11:15
	44.4	 11.05	   10:12:12
	44.3	 11.07	   10:33:00
	44	     11.2	   10:34:00
}
\end{verbatim}

\subsection{Serving aggregation requests}
We use the retrofit2 framework based on OKHTTP to handle communication with our REST server. An HTTP Interceptor is used to modify incoming and outgoing requests. In the former case, the interceptor decrypts the requests body using the private key of the installation before the body is parsed into Java Objects. The latter is used to add authentication to outgoing requests.
The app polls for new aggregation requests on a regular basis. New aggregation requests are first saved locally to the database, then processed and again stored locally and finally send back to the server. This separation of concerns is useful especially in case of an interrupted communication during processing the aggregation request. //TODO: Image with repository.
The aggregation itself takes the type parameter to specify which actions to take on the three fields (nn:int, value:Float, valueList: List<Float>) shared across all aggregation request types. In case of the tyes "steps" and "activity\_X" the field value contains the mean and the field n is the number of participants so far. In case of "stepsListing" only the field "valueList" is used and filled with the mean value of each user. In case of "trajectories", only the field "valueList" is used. Four subsequent elements of the list always represent one trajectory as of latitude of start, longitude of start, latitude of end and longitude of end.

\subsection{API}
The API is designed as a pure JSON API.
The API consists of the following endpoints:
\begin{itemize}
	\item POST /user - for creating a new user
	\item GET /requests - for retrieving aggregation requests for a user
	\item POST /forward - for sending a processed aggregation request back to the server
	\item GET /aggregations - for retrieving all completed aggregation results
	\item POST /admin/sampleRequest - for starting a new aggregation request.
\end{itemize}

The routes used for interaction with the application (except the one for creating a new user) are secured and can only be used if the users can successfully be authenticated. The routes for starting new aggregation requests and retrieving all results require administration authentication. The route for the results was designed to be available to the public without authentication but restricted in our setting to avoid privacy issues that might evolve due to the experimental request.
Figure XX depicts an example usage of each of those endpoints. There are some other routes that are only used for debugging purposes. 

\section{Data aggregation design}
All aggregation requests have in common that the underlying data is specified through start day and end day. Thus the minimum timespan for an aggregation is 24 hours. All other timespans are multiples of 24 hours.
The following aggregation requests were implemented:
\begin{enumerate}
	\item Computing the average number of steps walked.
	\item Computing the average time spent walking, in a vehicle or on a bicycle. \footnote{https://developers.google.com/android/reference/com/google/android/gms/location/DetectedActivity}
	\item Aggregating a list of the average number of steps walked during the timespan of each user.
	\item Aggregating a list of all trajectories registered by the users phone.
\end{enumerate}

We had no doubt that aggregation 1 and 2 do not pose any privacy risk to the users participating in the aggregation. Aggregation 3 was implemented to test whether this type of aggregation, which allows for more advances statistical computations as median values and distribution properties, still completely preserves privacy.
Aggregation 4 imposes a privacy risk discussed in XX on the user and was implemented in order to get an overview of the data quality of our setup and validate the feasability of the other aggregation requests proposed in XX.

\section{Server Design and Implementation}
The server is build using the event-driven node.js verion 10.15.3 leveraging the express \footnote{https://expressjs.com/} web-server framework and using the mocha \footnote{https://mochajs.org/} testing framework in combination with the chai \footnote{https://www.chaijs.com/} assertion library for unit and integration testing. The layered architecture starts with the server - server.js handling authentication and updating the respective users lastSeen property. Afterwards routes.js connects each API endpoint to the respective function in requests.js which contains the overall logic of the endpoint. The repository module than handles those requests according to the underlying datamodels and persists data in a mongoDB object store. server.js also invokes a scheduled task which re-routes stale requests where the user has not proceeded with the pending request either due to being offline or due to a problem handling the request. When new aggregation requests are started, the lastSeen timestamp of users is taken into account to exclude users that have not connected for a certain time. Furthermore, the list of users who are selected to serve the new request is ordered by the time the user was last seen.

\subsection{Data Model}
We organize the data in four collections\footnote{A collection in an object store is the equivalent to a table in a SQL database}. The user collection stores the user data which is the public key, the hashed password and "lastSeen" - the timestamp of the last interaction of the user with the server. Aggregation requests are split into two collections. The collection "rawAggregationRequests" stores the initial aggregation request inserted through the admin interface containing the fields start, end, type - the type of the request, the three fields n, value, valueList reused across all aggregations to pass data, the timestamp when the request was filed to the server and a flag indicating whether this request has been started yet\footnote{E.g. when the end data of a newly inserted aggregation request is in the future, the request will be started only when this day has passed}. Upon start of the aggregation request, a list of the 10 most recently active users is retrieved in order to serve this request. The request body is then encrypted with the first users public key and stored in the collection "aggregationRequests". Each time, a user requests an aggregationRequest, proceeds with it and sends the results back to the server, the result is inserted into the database as a new aggregationRequest. The fields of this collection are 
\begin{itemize}
	\item rawRequestId - The id of the related rawRequest. This field is not available through the API.
	\item started\_at - The timestamp, when the request has been started
	\item publicKey - The public key of the user that should proceed this request
	\item nextUser - The public key of the user that will receive the request afterwards. This is necessary so that the user that should proceed this request can encrypt the processed request with the public key of the next user.
	\item previousRequest - The id of the previous request. This is null, if it is the first request in the chain. This is used for the mechanism taking care if a request is not processed by the user it is pending for.
	\item users - the list of public keys of the following users that will proceed with this request. This field is not available through the API.
	\item encryptionKey - A synchronous key, encrypted with the public key of the user the request is aimed at.
	\item iv - the initialization vector used for synchronous encryption and decryption of the actual aggregation request.
	\item encryptedRequest - The actual aggregation request encrypted with the synchronous key.
	\item timestamp - The timestamp when this object has been created.
	\item commpleted - A flag indicating whether this aggregation request has already been proceeded by the respective user and the resulting aggregationRequest has been received by the server.
\end{itemize}
The last collection called "aggregationResults" is used to store the results of an aggregation request. Once there are no more users to serve an aggregationRequest, the last user sends the final data unencrypted to the server where it is stored as an aggregationResult. It contains the same fields as the rawAggregationRequest except the started flag and additionally a field started\_at and timestamp - indicating when the aggregation request referenced through rawRequestId was started and when it was completed.