% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}
\section{Motivation}

â€œData is the new oil" \parencite{data-is-the-new-oil, data-is-the-new-oil2} is a quote many people agree with. More and more businesses are based not on specific production capacities but on data and especially the ability to process it and the exclusive owenership over it. The success and monopoly of companies like Google, Facebook and Amazon can be attributed to this exclusive ownership at least to a reasonable extend.

While patents that used to power companies' success provide a balance through granting exclusive rights having to make the knowledge public, many companies e.g. Coca-Cola have decided successfully not to file for a patent and thus not having to reveal their knowledge \parencite{coca-cola}. If that approach is not compromised, it guarantees both, non-disclosure and  exclusive rights. Similarly, the non-disclosure of huge data sets collected by Facebook, Google and Amazon circumvent the balance intended by patents. But this unavailability of huge amounts of data to the public is an impediment of innovation and increased growth. For example, cities would benefit from aggregated location data in order to optimize traffic scheduling as also highlighted by Hoh et al. \parencite{hoh2005protecting} and Chatzimilioudis et al. \parencite{chatzimilioudis2012crowdsourcing}.
Nevertheless, the publication of raw data sets is impossible because it severly intrudes the privacy of the owners of the data.

So, even if companies would agree on a publication, a problem arises.
There is a conflict between preserving user privacy and publishing user data.
But in fact, users' privacy is already compromised even without publication of their data. Already the mere existence of central data sets pose a privacy risk to users, because security issues might allow for theft and unwanted publication of these data.
An example is the theft of 14 million users' data from facebook \parencite{facebook}.

Some governments and other institutions already publish some of their data sets after anonymizing them 
and there are crowdsourcing and open source approaches to make data available to everybody [CITE!!!]. 
Nevertheless, the applied anonymization is often not sufficient or at least critical if the resulting data set should still be useful. Research shows that inferences can be drawn from the published data sets that violate the respective users' privacy \parencite{cellphone, twitter}. Also, most research is based on data sets that span only over a few days or weeks. When collecting location data over longer periods, the chance of successful inference attacks increases in all cases with more data available. So, in addition to the privacy risk imposed on the user by the existence of a central data set, publishing anonymized data poses another risk to users' privacy.

\section{Research Questions}
In order to further investigate the trade-off between publication of location data and preservation of user privacy, we pose the following research questions:

\subsection*{RQ1: How is aggregation of location data possible without raw data being accessible to anybody but the owner?}
Previous work has shown that in order to overcome the conflict between privacy intrusion and (public) data availability, a solution is needed that works without storing raw data in a central data set.
This solution should eliminate the risk of leaking raw user data through theft from a centralized database. It should furthermore eliminate the risk of inference attacks on published believed-to-be-anonymized raw data if only aggregated data is stored on a central server. We investigate whether there is a solution and also what limitations this solution has, respectively which assumptions must hold for the solution to be valid.

\subsection*{RQ2: What types of aggregations can be published?}
Clearly, a mean value exposes less details about the underlying raw data than the whole distribution from which e.g. the median value and other percentiles can be computed. We will investigate how many details, respectively which statistical values can be published without user privacy being compromised.

\subsection*{RQ3: What is the risk of inference attacks on aggregated data due to overlappings in the covered timespan?}
Previous work has covered inference attacks on anonymized raw data sets. They have shown that inference attacks can be based on overlapping timespans or the same data set being published using different anonymization techniques. We will investigate, whether there is also a risk of inference attacks based on overlapping timespans in aggregated data and examine the limitations of publishing aggregated data.

\section{Contributions}
While most research follows the approach of degrading data in order to provide anonymity, we do not first collect the whole data set and then reduce it to a data set meeting privacy-constraints but we start from the bottom up. First, by performing aggregation in a decentralized manner and second by analyzing if an aggregation does not violate users' privacy pior to using this aggregation in a production environment. Step by step, the set of possible aggregations to be published could be extended after analyzing in a test environment if the respective aggregation does not intrude the users' privacy. The data stemming from those aggregations will then be available to the public. So, taking the distinction made by Brabham \parencite{brabham2008crowdsourcing} into account, our research will rather deal with open-sourcing than crowd-sourcing, once data is actually available to the public.

We investigate the possibility of storing raw location data only decentralized on the collecting devices. On a central database available to the public, only aggregated data is stored, thus, the privacy risk arising form a central database containing the overall raw data set is eliminated. Similar to previous research [CITE!!!], we assume the central server to be trusted and also the clients to be trusted. As the aggregation process happens decentrally, the central server will never hold any other than aggregated data and never know about individual raw data. 

Our research is organized as follows: First, we review related work in the areas of location privacy and anonymization techniques.
Chapter \ref{chapter:method} proposes our solution and outlines the general architecture of our approach using decentralized data analysis. Chapter \ref{chapter:design} documents the implementation of the setup proposed in Chapter \ref{chapter:method} and explains design decisions. We present the results of field testing our setup in Chapter \ref{chapter:performance}, Chapter \ref{chapter:conclusion} summarizes our work, discusses limitations as e.g. a trusted server, outlines possible future work and concludes with reproducability considerations.